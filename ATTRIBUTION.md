# ATTRIBUTION.md

**Last updated:** December 2025  
**This file was generated by ChatGPT 5.1, but cross-checked by me.**

---

## 1. Purpose of This Document

This document provides complete and transparent attribution for all external resources—documentation, data sources, and AI assistance—used in the development of this project.

---

## 2. Human Contribution Summary

All conceptual design decisions, feature engineering choices, model development steps, evaluation workflows, Streamlit UI structure, and explanatory writing were created by **me (the student)**.

External resources were referenced only for:

- Understanding API usage  
- Debugging  
- Confirming best practices  

All AI-generated content is explicitly marked.

---

## 3. External Documentation & Tutorials Referenced

I primarily relied on **official documentation sources** to look up function behavior, API syntax, and usage examples.  
If any documentation website included short tutorial pages or “getting started” examples, I may have used a few of those as well.  
These were limited to understanding how to properly use the library APIs and did **not** provide architecture-level code.

### 3.1 Python & Scientific Computing

- Python Standard Library Documentation  
- NumPy Documentation (https://numpy.org)  
- pandas Documentation (https://pandas.pydata.org)

### 3.2 Machine Learning Frameworks

#### TensorFlow / Keras Documentation
- Used for model definition, saving/loading, and understanding Sequential API behavior.  
- May have referenced brief tutorial pages included within the documentation site.

#### scikit-learn Documentation
Used for:
- Scalers (`StandardScaler`, `RobustScaler`)  
- Model evaluation metrics  
- Train-validation-test splitting  
- General ML workflows  

Tutorial-like examples included on the documentation site may also have been referenced.

#### imbalanced-learn Documentation (imblearn)
- Used for understanding resampling methods such as SMOTE or RandomUnderSampler (if applied).  
- Documentation examples and short tutorials may have been consulted.

### 3.3 Streamlit Documentation

- Official Streamlit API Reference  
- Used to correctly implement UI widgets such as `slider`, `radio`, and `number_input`.  
- Some documentation-site examples may have been referenced to understand recommended usage patterns.

### 3.4 Serialization / Utilities

- joblib Documentation  
- Used for saving and loading fitted scalers.

**No unverified or third-party blogs, YouTube tutorials, or code repositories were used.**

---

## 4. Dataset Attribution

This project uses the Heart Disease dataset hosted on Kaggle:

- **Dataset:** Heart Disease Dataset  
- **URL:** https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset/data  

**Notes:**

- I did not create or modify this dataset beyond preprocessing needed for modeling.  
- I used the dataset solely for model training and evaluation.  
- Attribution above reflects the dataset provider and hosting platform.

---

## 5. AI Assistance (ChatGPT 5.1) Attribution

AI assistance was limited to:

- Debugging  
- Error explanation  
- Code generation only where explicitly noted in the files  

I retained full authorship over all project decisions and implementations.

### 5.1 ChatGPT-generated Code

All AI-generated code appears in the repository with explicit comments such as: "Method generated by ChatGPT 5.1 on 12/10/25" or "Line of code generated by ChatGPT 5.1 on 12/10/25"

### Locations include:

---

#### **`src/app.py`**

**ChatGPT 5.1 contributed to:**

- The `translate_user_values` method  
- Code for loading `standard_scaler.pkl` and `robust_scaler.pkl`  
- Construction of the NumPy array `translated_values_array`  

**All other logic**—including UI design, scaling pipeline integration, feature engineering, and the control flow of prediction—**was authored by me.**

---

#### **Training Notebook (`run_and_train_heart_disease_detection_model.ipynb`)**

Within this notebook, ChatGPT 5.1 contributed only to specific lines and helper functions that are explicitly annotated with comments such as: "Line of code generated by ChatGPT 5.1 on 12/10/25" and "Following two lines of code generated by ChatGPT 5.1 on 12/10/25"

In particular, ChatGPT 5.1 contributed to:
- Import lines such as:
    - import tensorflow as tf
    - import random
- The block that sets random seeds for reproducibility (e.g., os.environ["PYTHONHASHSEED"], random.seed(...), np.random.seed(...), tf.random.set_seed(...)).

- Parts of the preprocessing and evidence-of-impact section using RobustScaler, including:
   - Lines computing summary statistics such as after_median, after_iqr and related print statements that report medians and interquartile ranges before vs. after scaling.
- Parts of the TensorFlow training utilities, including:
    - Configuration of the EarlyStopping callback inside train_tf_model (e.g., EarlyStopping(..., restore_best_weights=True, ...)).
- The line (and closely related logic) that extracts final validation metrics from the Keras History object, such as:
      - validation_accuracy = train_history.history['val_accuracy'][-1]

- XGBoost training pipeline and evaluation function

- The helper function to dump fitted scalers using joblib:
   - joblib.dump(fitted_stand_scaler, "standard_scaler.pkl")
   - joblib.dump(fitted_rob_scaler, "robust_scaler.pkl")

All of these contributions are individually marked in the notebook with comments indicating ChatGPT 5.1’s involvement.

All other notebook code—including:
- The overall data-loading function and missing-value checks
- Feature engineering logic
- The preprocessing pipeline that uses StandardScaler, SMOTE, and RobustScaler
- The custom TensorFlow MLP architecture in create_tf_model
- LogisticRegressionCV training pipeline and evaluation function
- The overall main() training pipeline orchestration


---

## 6. No External Code Copied

I did **not** copy code from:

- GitHub repositories  
- Kaggle notebooks  
- StackOverflow answers  
- Third-Party Blogs or tutorials

Only documentation and documentation-site tutorials were referenced for API understanding.

All final implementation code is **original or explicitly attributed to ChatGPT**.

---

## 7. Summary & Verification

This file was generated by ChatGPT 5.1, then reviewed and verified by me for accuracy.

All external sources consulted—including documentation, documentation-site tutorials, dataset providers, and AI-generated code—are transparently disclosed.

All AI-generated lines in the project code are explicitly marked.